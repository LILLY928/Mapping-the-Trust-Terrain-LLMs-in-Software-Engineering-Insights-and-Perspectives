# -*- coding: utf-8 -*-
"""Springer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uvKoX0j66LPPAmZRnyLlsI87dDxSXjOg

## Code crawling for Springer

* Keyword: (trust OR distrust OR trustworthiness) AND (SE OR Software Engineering) AND (LLM OR Large Language Model OR LLMs OR Large Language Models OR Deep Learning OR Machine Learning)

* Additional criteria:
  * Content type: research article, review article
  * Language: english
  * Diciplines: computer science, engineering
  * First: 1000 results
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd
from ast import keyword

from google.colab import drive
drive.mount('/content/drive')

results = []
# springer's page number start with 1
i = 1 #pagination start

while i <= 50: # pagination end
  try:
    url=('https://link.springer.com/search?new-search=true'
    +'&query=%28trust+OR+distrust+OR+trustworthiness%29+AND+%28SE+OR+Software+Engineering%29+AND+%28LLM+OR+Large+Language+Model+OR+LLMs+OR+Large+Language+Models+OR+Deep+Learning+OR+Machine+Learning%29'
    +'&content-type=Research&content-type=Review&language=En&facet-discipline=%22Computer+Science%22&&facet-discipline=%22Engineering%22&sortBy=relevance&page='+str(i))
    content = requests.get(url).text
    page = BeautifulSoup(content, 'html')

    for entry in page.find_all('div', attrs={"class": "c-card-open__main"}):
      title = entry.find('h3', attrs={'class': 'c-card-open__heading'})
      abst = entry.find('div', attrs={'class': 'app-listing__intro'})
      author = entry.find('div', attrs={'class': 'c-card-open__authors'}).find('span',attrs={'data-test':'authors'})
      conference = entry.find('div', attrs={'class': 'c-card-open__authors'}).find('a',attrs={'class':'u-color-inherit'})
      date = entry.find('div',attrs={'class':'c-card-open__meta'}).find('span',attrs={'data-test':'published'})

      results.append({"title": title.text.strip(),
                      "url":'https://link.springer.com'+entry.a['href'],
                      'authors':author.text.strip(),
                      'date':date.text.strip()[-5:],
                      'conference':conference.text.strip(),
                      'abstract':abst.text.strip()
                      })
  except:
      print("An exception occurred")
      print(i)
  i=i+1

Springer_df = pd.DataFrame(results)

Springer_df.head()

Springer_df.to_csv('/content/drive/MyDrive/Paper_crawing/Springer_data.csv', index=False)