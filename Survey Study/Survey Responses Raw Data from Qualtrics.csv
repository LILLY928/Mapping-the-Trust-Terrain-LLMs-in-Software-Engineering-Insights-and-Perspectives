Progress,Duration (in seconds),Finished,Distribution Channel,User Language,How many years of experience do you have using LLMs for Software Engineering tasks?,For which Software Engineering tasks have you used LLMs? Please check all that apply. - Selected Choice,For which Software Engineering tasks have you used LLMs? Please check all that apply. - Other (please specify) - Text,Which of the following LLMs (or versions of LLMs) have you used in Software Engineering research? Please select all that apply. - Selected Choice,Which of the following LLMs (or versions of LLMs) have you used in Software Engineering research? Please select all that apply. - Other (please specify) - Text,How often do you use LLMs for Code Generation tasks in a typical week?,"Please indicate to what extent you agree with the statement: 
""I generally trust LLMs on Code Generation tasks""",Which of the following factors are likely to influence your trust in LLMs on Code Generation tasks? Please select all that apply. - Selected Choice,Which of the following factors are likely to influence your trust in LLMs on Code Generation tasks? Please select all that apply. - Other (please specify) - Text,"In your own words, how would you define ""TRUST"" in LLMs for Code Generation?","Among [QID137-ChoiceGroup-SelectedChoicesTextEntry], do you trust some of these models for Code Generation tasks more than others?","Among [QID137-ChoiceGroup-SelectedChoicesTextEntry], which model(s) do you trust more for Code Generation tasks and why?",How often do you review the code generated by LLMs?,Do you review the code generated by LLMs differently from code written by humans?,"How do you typically review the code written by humans? For example, describe the steps you take, and the key aspects you aim to verify during the process.","How do you typically review the code generated by LLMs? For example, describe the steps you take, and the key aspects you aim to verify during the process.",How would you measure TRUST in code generated by LLMs?,How often do you use LLMs for Test Case Generation tasks in a typical week?,"Please indicate to what extent you would agree with the statement: 
""I generally trust LLMs on Test Case Generation tasks.""",Which of the following factors is likely to influence your trust in LLMs on Test Case Generation tasks? Please select all that apply. - Selected Choice,Which of the following factors is likely to influence your trust in LLMs on Test Case Generation tasks? Please select all that apply. - Other (please specify) - Text,"In your own words, how would you define TRUST in LLMs for Test Case Generation?","Among [QID137-ChoiceGroup-SelectedChoicesTextEntry], do you trust some of these models for Test Case Generation tasks more than others?","Among [QID137-ChoiceGroup-SelectedChoicesTextEntry], which model(s) do you trust more for Test Case Generation tasks and why?",How often do you review the test cases generated by LLMs?,Do you review the test cases generated by LLMs differently from those written by humans?,"How do you typically review the test cases written by humans? For example, describe the steps you take, and the key aspects you aim to verify during the process.","How do you typically review the test cases generated by LLMs? For example, describe the steps you take, and the key aspects you aim to verify during the process.",How would you measure TRUST in Test Cases generated  by LLMs?,How often do you use LLMs for automatic Program Repair tasks in a typical week?,"Please indicate to what extent you would agree with the statement:

 ""I generally trust LLMs on Program Repair tasks.""",Which of the following factors is likely to influence your trust in LLMs on Program Repair tasks? Please select all that apply. - Selected Choice,Which of the following factors is likely to influence your trust in LLMs on Program Repair tasks? Please select all that apply. - Other (please specify) - Text,"In your own words, how would you define TRUST in LLMs for Program Repair?","Among [QID137-ChoiceGroup-SelectedChoicesTextEntry], do you trust some of these models for Program Repair tasks more than others?","Among [QID137-ChoiceGroup-SelectedChoicesTextEntry], which model(s) do you trust more for Program Repair tasks and why?",How often do you review the program repairs generated by LLMs?,Do you review the program repairs generated by LLMs differently from those written by humans?,"How do you typically review the program repairs written by humans? For example, describe the steps you take, and the key aspects you aim to verify during the process.","How do you typically review the program repairs  generated by LLMs? For example, describe the steps you take, and the key aspects you aim to verify during the process.",How would you measure TRUST in Program Repairs generated by LLMs?,"Please indicate to what extent you agree with the statement: 
""It is important to establish the concept of trust in using LLMs in Software Engineering.""",Which measurement do you believe is more effective in capturing trust in LLMs in Software Engineering?,"In your opinion, is there a distinction between trust and trustworthiness when it comes to LLMs in Software Engineering?",Please describe the distinction between trust and trustworthiness in LLMs in Software Engineering?,What is your current job title? - Selected Choice,What is your current job title? - Other (please specify) - Text,What is the highest level of school you have completed or the highest degree you have received?,How many years of experience do you have with Software Engineering?,Please select the age range that best represents you:,What is your sex? - Selected Choice,What is your sex? - Other (please specify) - Text,"Do you identify as Spanish, Hispanic, or Latino?",What is your race or ethnicity? Please select all that apply. - Selected Choice,What is your race or ethnicity? Please select all that apply. - Other (please specify) - Text
100,1225,TRUE,anonymous,EN,3-5 years,"Code Generation (i.e., code completion),Code Summarization (i.e., generate description from source code),Test Case Generation (i.e., unit test generation),Program Repair (i.e., bug fixing)",,"Copilot,GPT-4",,Always (6-7 days a week),Agree,"Accuracy (i.e., outputs that the models generate are consistently correct),Interpretability (i.e., intentions/decisions of the model are comprehensible),Robustness (i.e., the model acts reliably under diverse scenarios)",,"1. Unlikely to make mistakes.
2. Provide more information/knowledge than I know or even more than what I can search. ",Yes,GPT-4. It is a more advanced LLM to my understanding. It has more logic reasoning capability. ,Often,Yes,"Code review in Github as pull requests. I read their code, but I feel it takes a very long time for me to understand them. But I do not have enough time to review everything. ","LLM-generated code is in small trunks and is continuous with what I was writing. So I read the code as it generates. It is much faster than reading human code. I verify if the logic is correct, especially if the logic is doing what I want. ",The likelihood that I accept the code without fully understand the code. ,Rarely (less than 1 day a week),Agree,"Accuracy (i.e., outputs that the models generate are consistently correct),Robustness (i.e., the model acts reliably under diverse scenarios)",,I trust LLMs for test generation if it can generate a rich set of tests. ,Unsure,,Always,No,,,The duration that I spend on carefully reading the test cases. ,Rarely (less than 1 day a week),Disagree,"Accuracy (i.e., outputs that the models generate are consistently correct),Interpretability (i.e., intentions/decisions of the model are comprehensible)",,"I trust LLM for program repair when it has a good likelihood of solving the problem. However, I consider program repair to be much harder than code generation. Experienced programmers can break down code generation tasks into small ones so LLM can generate code pretty accurately. But program repair requires much more contextual information. ",Yes,"I trust Copilot more. Because Copilot can see more context than GPT-4. For GPT-4, I have to copy and paste code to the dialogue box. So I can only input a small piece of code. ",Always,Unsure,,,The times that I spent on carefully read the repairs generated by LLM. ,Neither agree nor disagree,"Multi-item measurement of diverse factors, such as  accuracy, interpretability, robustness, ethics, etc.      ",Yes,Trust is for users and trustworthiness is a property of LLM. ,Professor,,Graduate or professional degree,More than 5 years,25 to 34,Male,,None of these,Asian,
100,1265,TRUE,anonymous,EN,1-2 years,"Code Generation (i.e., code completion),Code Summarization (i.e., generate description from source code),Program Repair (i.e., bug fixing)",,"Copilot,GPT-3.5,GPT-4",,Occasionally (1-2 days a week),Agree,"Accuracy (i.e., outputs that the models generate are consistently correct),Controllability (i.e., behavior of the model can be directed by humans),Robustness (i.e., the model acts reliably under diverse scenarios),Endorsement (i.e., other engineers/organizations have endorsed the model)",,The generated code fulfilled my requirements and the code is bug free.,Yes,Copilot,Always,Yes,"I will first check the method name, related documentation, arguments, and return values. Then I will check the structure of the code. For example, does the code contain too many loops or if-else statements? Then I will check if there exist any unused variables. Finally, I will run the test cases.",I would do mostly the same thing. However I noticed that many LLM-generated codes are meaningless and require extra time to understand what AI wants to do.,I trust the code if it does want I want it to do.,,,,,,,,,,,,,Rarely (less than 1 day a week),Agree,"Accuracy (i.e., outputs that the models generate are consistently correct),Interpretability (i.e., intentions/decisions of the model are comprehensible),Endorsement (i.e., other engineers/organizations have endorsed the model)",,"The LLM model can help me detect the bug and fix the bug, and I can confirm that the bug does exist.",Unsure,,Frequently,Unsure,,,"I will still run the test cases to make sure the program passes all the test cases. If one LLM model fails too many times, I would not trust that LLM model.",Somewhat agree,"Single-item measurement  e.g., a score from 1 (no trust) to 5 (complete trust) for trust in LLMs in Software Engineering  ",No,,Student,,Graduate or professional degree,3-5 years,25 to 34,Male,,None of these,Asian,
100,5971,TRUE,anonymous,EN,Less than 1 year,"Program Repair (i.e., bug fixing)",,GPT-3.5,,,,,,,,,,,,,,,,,,,,,,,,,,Rarely (less than 1 day a week),Disagree,"Accuracy (i.e., outputs that the models generate are consistently correct),Ethicality (i.e., the model protects data and adheres to moral standards),Other (please specify)",My coding skill will degrade if I use it too often,"I think LLM is a good reference, but I wouldn't use it too frequently. First of all, it gave me incorrect codes, and secondly, I don't want machines to take over my jobs.",,,Always,Yes,"Normally, I use inline forums like Stackoverflow, and I typically trust their codes because you can see the number of upvotes, meaning that other people also trust the code.","I will probably see if there are any syntax errors or other obvious errors first. From my experience, sometimes chatGPT makes up code that is not working.","I don't measure trust when I use LLM. I always assume it might be a good reference, but I won't trust it until I found it working.",Somewhat agree,"Multi-item measurement of diverse factors, such as  accuracy, interpretability, robustness, ethics, etc.      ",No,,Researcher,,Graduate or professional degree,3-5 years,25 to 34,Male,,None of these,Asian,
100,846,TRUE,anonymous,EN,Less than 1 year,"Code Generation (i.e., code completion),Program Repair (i.e., bug fixing)",,"Copilot,GPT-4",,Frequently (3-5 days a week),Neutral,"Accuracy (i.e., outputs that the models generate are consistently correct),Controllability (i.e., behavior of the model can be directed by humans),Robustness (i.e., the model acts reliably under diverse scenarios)",,It can generate the code that follows my requirements. And it can pass my test cases ,Unsure,,Always,No,,,"First, review the code to see if it is correct. Then, use some test cases to test. ",,,,,,,,,,,,,Frequently (3-5 days a week),Highly Agree,"Accuracy (i.e., outputs that the models generate are consistently correct),Controllability (i.e., behavior of the model can be directed by humans),Interpretability (i.e., intentions/decisions of the model are comprehensible),Robustness (i.e., the model acts reliably under diverse scenarios)",, the confidence that the LLMs can identify and fix bugs in code correctly ,Unsure,,Always,No,,,The rate of generated fixes that resolve the identified bugs successfully .,Neither agree nor disagree,"Multi-item measurement of diverse factors, such as  accuracy, interpretability, robustness, ethics, etc.      ",No,,Student,,Graduate or professional degree,More than 5 years,25 to 34,Female,,None of these,Asian,
100,541,TRUE,anonymous,EN,1-2 years,"Code Generation (i.e., code completion),Code Summarization (i.e., generate description from source code)",,"BERT,Copilot,GPT-3,GPT-3.5,GPT-4,LLaMa",,Frequently (3-5 days a week),Agree,"Accuracy (i.e., outputs that the models generate are consistently correct),Controllability (i.e., behavior of the model can be directed by humans),Interpretability (i.e., intentions/decisions of the model are comprehensible),Robustness (i.e., the model acts reliably under diverse scenarios)",,"Accuracy, transparency, and security of the generated code.",No,,Always,No,,,Not sure,,,,,,,,,,,,,,,,,,,,,,,,,Strongly agree,"Multi-item measurement of diverse factors, such as  accuracy, interpretability, robustness, ethics, etc.      ",Unsure,,Student,,Bachelor's degree,1-2 years,25 to 34,Male,,None of these,Asian,
100,1601,TRUE,anonymous,EN,1-2 years,"Code Generation (i.e., code completion),Code Summarization (i.e., generate description from source code)",,"GPT-3,GPT-3.5,GPT-4",,Rarely (less than 1 day a week),Neutral,"Accuracy (i.e., outputs that the models generate are consistently correct),Controllability (i.e., behavior of the model can be directed by humans),Robustness (i.e., the model acts reliably under diverse scenarios),Workflow integration (i.e., the model can easily be integrated to existing development practices)",,The degree of confidence in using a piece of code generated by an LLM while having the complete knowledge on the context of the codebase on my end.,Yes,"I would feel more confident in using GPT-4 because it can take as input a complete codebase with multiple files at a time, which enables the model to have a complete picture.",Always,Unsure,,,By usability of the generated code.,,,,,,,,,,,,,,,,,,,,,,,,,Somewhat agree,"Multi-item measurement of diverse factors, such as  accuracy, interpretability, robustness, ethics, etc.      ",Yes,I may trust a piece of code generated by an LLM based on its usability but it does not make that LLM trustworthy for every encounter. ,Student,,Bachelor's degree,3-5 years,25 to 34,Female,,None of these,Asian,
100,883,TRUE,anonymous,EN,1-2 years,"Code Generation (i.e., code completion),Code Summarization (i.e., generate description from source code),Test Case Generation (i.e., unit test generation),Program Repair (i.e., bug fixing)",,"GPT-3,GPT-3.5,GPT-4,Other (please specify)",CodeGen,Occasionally (1-2 days a week),Agree,"Accuracy (i.e., outputs that the models generate are consistently correct),Controllability (i.e., behavior of the model can be directed by humans),Robustness (i.e., the model acts reliably under diverse scenarios)",,"Trust in LLMs for Code Generation is how accurately and efficiently an LLM can produce code that is essentially or almost correct, and easily fixed by programmer intervention, without many errors.",Yes,"For complex tasks, I would trust GPT-4 if it were available reliably, as it is better at higher-level reasoning, with GPT-3.5 being my go-to LLM.",Always,Yes,"Code written by humans is usually functionally done, barring minor bugs. I verify edge cases, and look at the general feel of code.","Code generated by LLMs is automatically suspicious in many aspects, such as syntax, style, and functionality; the code I take generated from LLMs is almost never used wholesale, and is repurposed and used only as a skeleton for the final product.",I would measure trust in code generated by LLMs by assessing the degree to which I must change the code for it to suit my purposes.,Rarely (less than 1 day a week),Agree,"Accuracy (i.e., outputs that the models generate are consistently correct),Controllability (i.e., behavior of the model can be directed by humans),Interpretability (i.e., intentions/decisions of the model are comprehensible),Ethicality (i.e., the model protects data and adheres to moral standards)",,Trust in LLMs for Test Case Generation involves accurately and precisely producing meaningful test cases which insightfully test the provided function.,Yes,"GPT-3.5, because it's the best model that's reliably available of the provided options.",Always,Yes,I cursorily observe the proposed inputs and run the test cases to ensure they pass.,"I look at the proposed test cases more closely, checking for things like syntax and calling conventions, verifying the input is correctly being piped into the proposed function, as well as running the test cases to ensure they pass.",I would trust test cases the more they prove that my doubts about correct syntax and calling conventions do not apply.,Rarely (less than 1 day a week),Disagree,"Accuracy (i.e., outputs that the models generate are consistently correct),Controllability (i.e., behavior of the model can be directed by humans),Interpretability (i.e., intentions/decisions of the model are comprehensible),Robustness (i.e., the model acts reliably under diverse scenarios),Endorsement (i.e., other engineers/organizations have endorsed the model),Source reputation (i.e., reputation of the platform/individual introducing the model)",,"Trust in LLMs for Program Repair requires insightful, correct propositions with concise, logical reasoning and justifications for changes.",No,,Always,Yes,"I tend to trust humans a lot more - if a human says they fixed the issue, there is unlikely to be any significant flaws with their approach (unless said human has a reputation of being erroneous).","I scrutinize the proposed program repair output of LLMs very highly, as they can often give wildly incorrect approaches (both in function and in style), and produce apparently-sensible English justification which does not correspond to whether the changes actually make sense.","I measure trust in program repairs not very much, only as evidenced by consistent and accurate program repairs - and I would not trust LLMs with complex debugging tasks.",Somewhat agree,"Multi-item measurement of diverse factors, such as  accuracy, interpretability, robustness, ethics, etc.      ",Unsure,,Freelancer,,Graduate or professional degree,More than 5 years,18 to 24,Male,,None of these,"Native Hawaiian or Pacific Islander,White",
100,127,TRUE,anonymous,EN,No experience,Other (please specify),none yet,Other (please specify),I've heard of several of these but haven't used any in software development,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Strongly agree,"Multi-item measurement of diverse factors, such as  accuracy, interpretability, robustness, ethics, etc.      ",Unsure,,Other (please specify),I'm currently a PhD student and also hold a job as a software developer,Bachelor's degree,1-2 years,25 to 34,Male,,None of these,Asian,
100,13555,TRUE,anonymous,EN,1-2 years,"Code Generation (i.e., code completion),Program Repair (i.e., bug fixing)",,"BERT,CodeT5+,Copilot",,Frequently (3-5 days a week),Agree,"Accuracy (i.e., outputs that the models generate are consistently correct),Community engagement (i.e., an existing community has used the model and can offer additional support),Workflow integration (i.e., the model can easily be integrated to existing development practices),Ethicality (i.e., the model protects data and adheres to moral standards),Source reputation (i.e., reputation of the platform/individual introducing the model)",,"If the logic is correct and pass all the tests, i'll trust them",Yes,Copilot,Often,No,,,I do not have an idea to measure the trust to be honest. (May if the code generation comes with community voting or something),,,,,,,,,,,,,Rarely (less than 1 day a week),Agree,"Accuracy (i.e., outputs that the models generate are consistently correct),Interpretability (i.e., intentions/decisions of the model are comprehensible),Community engagement (i.e., an existing community has used the model and can offer additional support),Workflow integration (i.e., the model can easily be integrated to existing development practices),Ethicality (i.e., the model protects data and adheres to moral standards),Source reputation (i.e., reputation of the platform/individual introducing the model)",,"According to my understanding, Trust in LLM for program repair is providing reliable answers which are accepted by the community like stack over flow or reliable static analysis tools. ",Yes,CoPilot,Occasionally,No,,,"If the generated program repair is following the industry standards, will trust them.",Strongly agree,"Multi-item measurement of diverse factors, such as  accuracy, interpretability, robustness, ethics, etc.      ",Unsure,,Student,,Bachelor's degree,3-5 years,25 to 34,Male,,None of these,Asian,
100,605,TRUE,anonymous,EN,Less than 1 year,"Code Generation (i.e., code completion),Vulnerability Detection (i.e., find vulnerable code)",,Other (please specify),Don't recall,Rarely (less than 1 day a week),Neutral,"Accuracy (i.e., outputs that the models generate are consistently correct),Interpretability (i.e., intentions/decisions of the model are comprehensible),Source reputation (i.e., reputation of the platform/individual introducing the model)",,I would consider trust to mean that I would be comfortable including the LLM generate code into a code review packet without feeling the need to verify the code in advance.,,,Rarely,Unsure,,,I would likely gauge trust in LLM generated code based on the amount of code generated over time that does/does not require modification for proper execution.,,,,,,,,,,,,,,,,,,,,,,,,,Strongly agree,"Multi-item measurement of diverse factors, such as  accuracy, interpretability, robustness, ethics, etc.      ",No,,Manager,,Graduate or professional degree,More than 5 years,55 to 64,Male,,None of these,White,
100,816,TRUE,anonymous,EN,3-5 years,"Code Generation (i.e., code completion),Code Summarization (i.e., generate description from source code),Program Repair (i.e., bug fixing),Vulnerability Detection (i.e., find vulnerable code)",,"BERT,T5,CodeT5,Copilot,Other (please specify)",Gemini,Always (6-7 days a week),Neutral,"Accuracy (i.e., outputs that the models generate are consistently correct),Workflow integration (i.e., the model can easily be integrated to existing development practices)",,How often I accept the generated code without intense scrutiny,Yes,Copilot and Gemini,Often,No,,,"Percent of times that the generated code held the ""test of time"", ie become part of the codebase without futher edits.",,,,,,,,,,,,,Rarely (less than 1 day a week),Disagree,"Accuracy (i.e., outputs that the models generate are consistently correct),Interpretability (i.e., intentions/decisions of the model are comprehensible),Workflow integration (i.e., the model can easily be integrated to existing development practices)",,"The LLM knows when to say ""don't know"" and has low false positives.",No,,Always,Unsure,,,By the amount of time it has saved me over the amount of time I have lost trying to get a good response OR wasted in debugging errors that it introduced,Somewhat agree,"Multi-item measurement of diverse factors, such as  accuracy, interpretability, robustness, ethics, etc.      ",Unsure,,Researcher,,Graduate or professional degree,More than 5 years,35 to 44,Male,,None of these,White,
77,14,FALSE,qr,EN,1-2 years,"Test Case Generation (i.e., unit test generation)",,GPT-3.5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
33,36,FALSE,anonymous,EN,1-2 years,"Code Generation (i.e., code completion),Code Summarization (i.e., generate description from source code),Test Case Generation (i.e., unit test generation)",,"BERTOverflow,T5,CodeT5",,Occasionally (1-2 days a week),Highly Agree,"Interpretability (i.e., intentions/decisions of the model are comprehensible),Workflow integration (i.e., the model can easily be integrated to existing development practices)",,No ndnsndmfk,No,,Rarely,No,,,Mmfmfmfmf,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
100,1413,TRUE,anonymous,EN,1-2 years,"Code Generation (i.e., code completion),Code Summarization (i.e., generate description from source code)",,"Copilot,GPT-3,GPT-3.5,GPT-4",,Rarely (less than 1 day a week),Agree,"Accuracy (i.e., outputs that the models generate are consistently correct),Controllability (i.e., behavior of the model can be directed by humans),Interpretability (i.e., intentions/decisions of the model are comprehensible),Endorsement (i.e., other engineers/organizations have endorsed the model)",,"I typically use such tools for smaller code snippets, so I would say that I trust the tools if I can understand the snippet and how it functions for myself and believe that it can successfully accomplish the desired task without introducing errors or other vulnerabilities. In other words, my trust is based on the tool's ability to consistently and reliably generate correct, understandable outputs.",No,,Often,Yes,"When reviewing human-written code, my focus is typically on 1) verifying that the code successfully accomplishes the desired task, and 2) checking that the changes do not introduce bugs or adversely affect other parts of the system. This can involve reading (or sometimes, truthfully, skimming) over the code, running it for myself to check the functionality, and checking impacted components that were not directly altered.","My process for reviewing LLM-generated code is slightly different, as it adds an earlier step to check for hallucinations. For smaller snippets, a quick but deliberate check of the output can usually identify any libraries, etc. that the code tries to rely on, but do not actually exist. Beyond this, I typically devote more effort into understanding how the code functions than if a human wrote it. Especially since I typically deal with small snippets when using LLM-generated code, I don't typically have to do major impact analysis of code generated by these tools, but if there comes a time in which I generate a large amount of code at once, I imagine I would give a more thorough analysis than I would human-written code.","The measure of my trust is largely tied to the measure of my understanding of the code that is generated. If I see code that's largely opaque to me, I might give a human the benefit of the doubt as long as I can see that the product works as intended, but I'm still hesitant to extend that courtesy to AI-generated code, and will devote more effort to understanding it for myself. However, I admittedly use these tools to generate code only intermittently - perhaps with more time and first-hand experience, I'll learn to trust them more.",,,,,,,,,,,,,,,,,,,,,,,,,Somewhat agree,"Multi-item measurement of diverse factors, such as  accuracy, interpretability, robustness, ethics, etc.      ",Yes,"To me, ""trust"" accounts for my faith in an LLM to generate suitable code for a given task. ""Trustworthiness,"" on the other hand, seems to me to describe my faith in the LLM itself, inclusive of various tasks. The distinction, perhaps, lies in my perception of the model's robustness. However, I don't believe that the differences between ""trust"" and ""trustworthiness"" are all that great.",Student,,Graduate or professional degree,1-2 years,18 to 24,Male,,None of these,White,
100,166219,TRUE,anonymous,EN,3-5 years,"Code Summarization (i.e., generate description from source code),Vulnerability Detection (i.e., find vulnerable code)",,"BERT,CodeBERT,T5,CodeT5,LLaMa",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Strongly agree,"Multi-item measurement of diverse factors, such as  accuracy, interpretability, robustness, ethics, etc.      ",Yes,"Interesting question. Given the amazing capabilities of LLMs, we are willing to trust them to solve our SE problems. For example, when it generates a working piece of code against our natural language query, we trust it and might reuse the code in our project. However, if it later turns out to be buggy or vulnerable, the LLMs will lose their trustworthiness. I think LLMs have yet to prove their trustworthiness. ",Professor,,Graduate or professional degree,More than 5 years,35 to 44,Male,,None of these,Asian,
77,10735,FALSE,anonymous,EN,3-5 years,"Test Case Generation (i.e., unit test generation)",,T5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
3,81,FALSE,anonymous,EN,1-2 years,"Code Generation (i.e., code completion),Test Case Generation (i.e., unit test generation),Program Repair (i.e., bug fixing)",,"Claude,Copilot,GPT-4",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
100,343893,TRUE,anonymous,EN,3-5 years,"Code Generation (i.e., code completion),Code Summarization (i.e., generate description from source code)",,"BERT,Codex,LLaMa",,Occasionally (1-2 days a week),Neutral,"Accuracy (i.e., outputs that the models generate are consistently correct),Controllability (i.e., behavior of the model can be directed by humans),Interpretability (i.e., intentions/decisions of the model are comprehensible),Robustness (i.e., the model acts reliably under diverse scenarios),Community engagement (i.e., an existing community has used the model and can offer additional support),Workflow integration (i.e., the model can easily be integrated to existing development practices),Endorsement (i.e., other engineers/organizations have endorsed the model),Ethicality (i.e., the model protects data and adheres to moral standards),Source reputation (i.e., reputation of the platform/individual introducing the model)",,"For me LLMs, especially for code generation would be trustworthy if it produces accurate results, is well-tested, and properly takes care of corner cases (interpretability).
 
Practically, trusting LLMs output can be tricky. I see code generation with LLMs as something that reduces the effort while coding. For simple(granular) functions, when I know what I want, I can trust the output because it's easy to check/verity. However, I have also encountered several scenarios where it's difficult to capture the requirements through a simple prompt. ",Yes,I have been recently using Code LLaMa. ,Always,Yes,"For code generated by humans, I tend to focus more on the overall structure. If there are comments describing what the code does, I trust the completeness of the code and focus more on whether I can improve the quality/performance or I can identify minor bugs. Additionally, I also give attention to any security issues that the code may introduce. ","First, I check if the code runs. While there has been rapid improvement on how LLMs behave (e.g., LLMs making stupid mistakes to LLMs providing detailed clarification on what the code does in each step), I still make sure that the function does what it is supposed to do.

After I know that the code works and my prompt sufficiently captures what I want the code to accomplish, I check for edge cases and security issues. If I know the code is doing what it is supposed to, I tend to trust the code quality in terms of following the best practices and even performance (e.g., efficiency), which I would be more careful if I were reviewing the code generated by humans. ",Running tests. ,,,,,,,,,,,,,,,,,,,,,,,,,Strongly agree,"Multi-item measurement of diverse factors, such as  accuracy, interpretability, robustness, ethics, etc.      ",Yes,"Trust in LLMs would be high confidence in LLMs being able to accomplish tasks based on experience of users.

Trustworthiness would be worthy of trust on the basis of certain criteria and characteristics.  For example, In the context of SE, trustworthiness in LLMs would be based on the design, use of dataset, implementation of LLMs, etc. ",Researcher,,Graduate or professional degree,More than 5 years,25 to 34,Male,,None of these,Asian,
100,120758,TRUE,anonymous,EN,1-2 years,"Code Generation (i.e., code completion),Code Summarization (i.e., generate description from source code),Test Case Generation (i.e., unit test generation)",,"GPT-3.5,GPT-4",,Rarely (less than 1 day a week),Disagree,"Accuracy (i.e., outputs that the models generate are consistently correct),Interpretability (i.e., intentions/decisions of the model are comprehensible)",,"Trust in LLMs for Code Generation could be interpreted as the percentage of accurate code generated within an extended time frame of use. Conversely, it is the degree of bugs generated in code within an extended time.",Unsure,,Always,No,,,% of bugs generated in code within a specific time frame.,Rarely (less than 1 day a week),Neutral,"Accuracy (i.e., outputs that the models generate are consistently correct),Controllability (i.e., behavior of the model can be directed by humans)",,Trust in LLM for test case generation is the degree of robustness of test cases generated and how accurately it mirrors the expected inputs.,Unsure,,Always,No,,,generated test cases / all possible test cases,,,,,,,,,,,,,Strongly agree,"Multi-item measurement of diverse factors, such as  accuracy, interpretability, robustness, ethics, etc.      ",Yes,"Trustworthiness is the ability of an LLM to perform software engineering tasks without failure, inaccuracy, or bugs. Trust is characteristic of an LLM to be capable of accomplishing software engineering tasks. ",Student,,Bachelor's degree,3-5 years,25 to 34,Male,,None of these,Black or African American,
1,4,FALSE,anonymous,EN,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,13,FALSE,anonymous,EN,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,1036,FALSE,anonymous,EN,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,290,FALSE,anonymous,EN,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
100,90,TRUE,anonymous,EN,Less than 1 year,"Code Summarization (i.e., generate description from source code)",,"GPT-3,LLaMa",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Strongly disagree,"Multi-item measurement of diverse factors, such as  accuracy, interpretability, robustness, ethics, etc.      ",Unsure,,Engineer,,Graduate or professional degree,More than 5 years,25 to 34,Male,,None of these,Asian,
10,762,FALSE,anonymous,EN,3-5 years,"Code Generation (i.e., code completion),Code Summarization (i.e., generate description from source code),Test Case Generation (i.e., unit test generation),Program Repair (i.e., bug fixing),Other (please specify)",Code review,"BERT,CodeBERT,T5,CodeT5,CodeT5+,Codex,Copilot,GPT-4,LLaMa",,,,,,,,,,,,,,,,,,,,,,,,,,Never,Highly Disagree,"Accuracy (i.e., outputs that the models generate are consistently correct),Interpretability (i.e., intentions/decisions of the model are comprehensible),Robustness (i.e., the model acts reliably under diverse scenarios),Endorsement (i.e., other engineers/organizations have endorsed the model),Source reputation (i.e., reputation of the platform/individual introducing the model)",,The degree of confidence I can put in received recommendations: The LLM should either output a correct solution or omitting proposing a solution.,Yes,"GPT-4: The natural language explanation it provides for the bug can at least help in understanding the rationale behind the implemented changes, thus making it simpler for the developer to accept/reject the recommendation. ",Never,Unsure,,,'- Percentage of recommendations accepted by developers using the LLM,,,,,,,,,,,,,,
100,99,TRUE,anonymous,EN,No experience,Other (please specify),I train LLMs for SE research.,"BERT,CodeBERT",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Strongly agree,"Multi-item measurement of diverse factors, such as  accuracy, interpretability, robustness, ethics, etc.      ",Unsure,,Professor,,Graduate or professional degree,More than 5 years,35 to 44,Female,,None of these,Asian,
100,378,TRUE,anonymous,EN,Less than 1 year,"Program Repair (i.e., bug fixing)",,GPT-4,,,,,,,,,,,,,,,,,,,,,,,,,,Rarely (less than 1 day a week),Agree,"Accuracy (i.e., outputs that the models generate are consistently correct),Controllability (i.e., behavior of the model can be directed by humans),Interpretability (i.e., intentions/decisions of the model are comprehensible),Robustness (i.e., the model acts reliably under diverse scenarios),Ethicality (i.e., the model protects data and adheres to moral standards)",,How much LLMs can reliably assist in finding and solving issues,,,Always,Yes,Usually I see alternatives from multiple people if possible as well as their detailed explanations to see if it looks right ,I go through the entire code ,How accurate results generally are,Strongly agree,"Multi-item measurement of diverse factors, such as  accuracy, interpretability, robustness, ethics, etc.      ",Yes,I think trust is mainly about the results accuracy while trustworthiness is more about reputation of the model/company,Student,,High school diploma or equivalent,3-5 years,18 to 24,Male,,None of these,Asian,
100,249,TRUE,anonymous,EN,Less than 1 year,"Code Generation (i.e., code completion),Code Summarization (i.e., generate description from source code)",,GPT-3.5,,Rarely (less than 1 day a week),Disagree,"Ethicality (i.e., the model protects data and adheres to moral standards)",,If LLM's are able to comprehend what tokens mean instead of just doing text prediction off of neural networks.,,,Rarely,Yes,I can actually ask them to go look something up or connect their understanding to their context which goes back years or even decades.  They also can be more interested/passionate about some topics and they'll put in more work to work on their own.  Also they don't need a power cord to work.,"1. Does it work?
2. Why doesn't it work?
3. Does prompting only show its limited capability?",I measure it by its ability to comprehend and not through neural networks,,,,,,,,,,,,,,,,,,,,,,,,,Strongly agree,"Multi-item measurement of diverse factors, such as  accuracy, interpretability, robustness, ethics, etc.      ",Unsure,,Engineer,,Bachelor's degree,1-2 years,25 to 34,Non-binary,,None of these,Prefer not to answer,
100,896,TRUE,anonymous,EN,Less than 1 year,"Code Generation (i.e., code completion)",,GPT-3.5,,Occasionally (1-2 days a week),Neutral,"Accuracy (i.e., outputs that the models generate are consistently correct),Controllability (i.e., behavior of the model can be directed by humans),Ethicality (i.e., the model protects data and adheres to moral standards)",,Trust is relying on LLMs to not intentionally try to undermine systems they generate code for.,,,Always,Yes,I follow the execution path of the code to get an idea of how it's working. I try to get an idea of the architectural decisions made by the programmer and why they made them. ,I scan through line by line and look for idiosyncrasies relative to the rest of the codebase. I attempt to understand if the LLM understood the problem trying to be solved.,By evaluating whether or not the generated code is maliciously trying to cause harm.,,,,,,,,,,,,,,,,,,,,,,,,,Neither agree nor disagree,"Multi-item measurement of diverse factors, such as  accuracy, interpretability, robustness, ethics, etc.      ",Unsure,,Engineer,,Bachelor's degree,1-2 years,18 to 24,Male,,None of these,White,
55,440488,FALSE,anonymous,EN,Less than 1 year,"Code Generation (i.e., code completion),Vulnerability Detection (i.e., find vulnerable code)",,GPT-3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
100,827,TRUE,anonymous,EN,1-2 years,"Code Generation (i.e., code completion),Code Summarization (i.e., generate description from source code),Program Repair (i.e., bug fixing)",,"Copilot,GPT-3.5",,Frequently (3-5 days a week),Agree,"Accuracy (i.e., outputs that the models generate are consistently correct),Robustness (i.e., the model acts reliably under diverse scenarios),Endorsement (i.e., other engineers/organizations have endorsed the model),Ethicality (i.e., the model protects data and adheres to moral standards),Source reputation (i.e., reputation of the platform/individual introducing the model)",,"Fundamentally I think that trust in this sense means that the code, test, or summary produced are accurate.  That is that if I produce a code snippet, the model hasn't hallucinated any modules and the snippet will actually accomplish the task specified in the prompt. 

I've had models try to gaslight me before into believing that a solution it provided did solve the problem I asked.  Just last week I spent an hour trying to debug a script I wrote with the assistance of Copilot.  I knew what I needed to write (it was a pretty basic line)so I just trusted the autocomplete and moved on.  It's very frustrating when you finally realize the culprit is that Copilot arbitrarily passed in the wrong variable as a parameter to a function...

It's also important that the output doesn't include any vulnerabilities or inefficiencies.  I would say that I would apply to trust to an LLM in a similar manner that I might apply it to a junior developer.",No,,Always,Unsure,,,"I think my primary metric would be correctness.  Without that, any output from the model is utterly useless.",,,,,,,,,,,,,Rarely (less than 1 day a week),Neutral,"Accuracy (i.e., outputs that the models generate are consistently correct),Robustness (i.e., the model acts reliably under diverse scenarios)",,"The repair should make the program more efficient, make the code easier to read, without changing its functionality.  At a bare minimum I need to be able to trust that the model won't alter the way the code behaves, potentially causing it to miss some edge case.",No,,Always,Unsure,,,"Again I think that accuracy is the main metric.  If the repaired code is broken, then there was no point in using the model.  Secondly, the repaired solution should be an improvement over the original.  If that is failed, then the repair was also useless.",Strongly agree,"Multi-item measurement of diverse factors, such as  accuracy, interpretability, robustness, ethics, etc.      ",Unsure,,Researcher,,Graduate or professional degree,More than 5 years,25 to 34,Male,,None of these,White,
48,557,FALSE,anonymous,EN,Less than 1 year,"Code Generation (i.e., code completion),Code Summarization (i.e., generate description from source code),Program Repair (i.e., bug fixing),Vulnerability Detection (i.e., find vulnerable code)",,"Copilot,GPT-3.5,GPT-4",,Occasionally (1-2 days a week),Neutral,"Accuracy (i.e., outputs that the models generate are consistently correct),Interpretability (i.e., intentions/decisions of the model are comprehensible),Robustness (i.e., the model acts reliably under diverse scenarios),Ethicality (i.e., the model protects data and adheres to moral standards),Source reputation (i.e., reputation of the platform/individual introducing the model)",,Trust in LLMS means I can use the code from LLMS directly in my study or work occasion.,Yes,"4, I paid ",Always,Unsure,,,More similar to human expert’s product more worthy to trust.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
40,148,FALSE,anonymous,EN,1-2 years,"Code Generation (i.e., code completion),Code Summarization (i.e., generate description from source code),Program Repair (i.e., bug fixing)",,"BERT,GPT-3,GPT-3.5,GPT-4,LLaMa",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
3,33,FALSE,anonymous,EN,1-2 years,"Code Generation (i.e., code completion),Code Summarization (i.e., generate description from source code),Test Case Generation (i.e., unit test generation),Program Repair (i.e., bug fixing)",,"Copilot,GPT-4",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,2,FALSE,anonymous,EN,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,12,FALSE,anonymous,EN,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
100,151,TRUE,anonymous,EN,No experience,Other (please specify),none,Other (please specify),None,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Strongly agree,"Multi-item measurement of diverse factors, such as  accuracy, interpretability, robustness, ethics, etc.      ",Yes,.,Engineer,,Bachelor's degree,1-2 years,25 to 34,Male,,None of these,Prefer not to answer,
95,1615,FALSE,anonymous,EN,No experience,"Code Generation (i.e., code completion)",,Claude,,Rarely (less than 1 day a week),Disagree,"Interpretability (i.e., intentions/decisions of the model are comprehensible)",,test,,,Occasionally,No,,,t,,,,,,,,,,,,,,,,,,,,,,,,,Neither agree nor disagree,"Multi-item measurement of diverse factors, such as  accuracy, interpretability, robustness, ethics, etc.      ",No,,,,,,,,,,,
40,64,FALSE,anonymous,EN,1-2 years,"Code Generation (i.e., code completion),Code Summarization (i.e., generate description from source code),Program Repair (i.e., bug fixing)",,"Copilot,GPT-3,GPT-3.5,GPT-4",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,36,FALSE,anonymous,EN,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
100,423,TRUE,anonymous,EN,Less than 1 year,"Code Summarization (i.e., generate description from source code),Vulnerability Detection (i.e., find vulnerable code)",,"CodeBERT,GPT-3,LLaMa",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Strongly agree,"Multi-item measurement of diverse factors, such as  accuracy, interpretability, robustness, ethics, etc.      ",Yes,Trust is more subjective than trustworthiness in my opinion. An LLM may be trustworthy but I may not trust it because I want to err on the side of caution.,Student,,Graduate or professional degree,More than 5 years,25 to 34,Female,,None of these,White,
100,1698,TRUE,anonymous,EN,1-2 years,"Code Generation (i.e., code completion),Code Summarization (i.e., generate description from source code),Test Case Generation (i.e., unit test generation),Program Repair (i.e., bug fixing)",,"CodeT5,Copilot,GPT-3.5,GPT-4",,Occasionally (1-2 days a week),Agree,"Accuracy (i.e., outputs that the models generate are consistently correct),Controllability (i.e., behavior of the model can be directed by humans),Interpretability (i.e., intentions/decisions of the model are comprehensible),Robustness (i.e., the model acts reliably under diverse scenarios),Community engagement (i.e., an existing community has used the model and can offer additional support),Workflow integration (i.e., the model can easily be integrated to existing development practices),Ethicality (i.e., the model protects data and adheres to moral standards),Source reputation (i.e., reputation of the platform/individual introducing the model)",,"The LLMs are pretty good at code generation for problem-solving questions, but not for building the applications using latest technology.",Unsure,,Always,Yes,"When reviewing code written by humans, I just look through the logic and if everything is well-integrated or not.","When reviewing code generated by LLMs, I look through logic, imports, versions of the packages, and all the linked file paths.","I measure it by accuracy, robustness, error handling, and comprehensibility. ",Never,Agree,"Accuracy (i.e., outputs that the models generate are consistently correct),Controllability (i.e., behavior of the model can be directed by humans),Interpretability (i.e., intentions/decisions of the model are comprehensible),Robustness (i.e., the model acts reliably under diverse scenarios),Community engagement (i.e., an existing community has used the model and can offer additional support)",,"I think LLMs do a pretty good job creating test cases for simple programs, but I am not sure about large applications.",Unsure,,Rarely,No,,,I would measure it by the accuracy and the coverage of test cases of the program.,Frequently (3-5 days a week),Agree,"Accuracy (i.e., outputs that the models generate are consistently correct),Controllability (i.e., behavior of the model can be directed by humans),Interpretability (i.e., intentions/decisions of the model are comprehensible),Robustness (i.e., the model acts reliably under diverse scenarios),Workflow integration (i.e., the model can easily be integrated to existing development practices),Endorsement (i.e., other engineers/organizations have endorsed the model),Ethicality (i.e., the model protects data and adheres to moral standards),Source reputation (i.e., reputation of the platform/individual introducing the model)",,"The LLMs should maintain the privacy of data, it should not use the data that are given as prompts for its training. If prompts are used for self-training, then the content's confidentiality is compromised, so I would not trust such LLMs.",Unsure,,Always,Unsure,,,I would measure TRUST by checking the accuracy and performance of the programs.,Strongly agree,"Multi-item measurement of diverse factors, such as  accuracy, interpretability, robustness, ethics, etc.      ",Yes,"Trust is when you are confident in what LLM is giving you. Whereas, trustworthiness is more like help you are getting but you are not confident in the answer given by them.",Student,,Bachelor's degree,1-2 years,25 to 34,Female,,None of these,Asian,
100,798,TRUE,anonymous,EN,Less than 1 year,"Code Generation (i.e., code completion),Program Repair (i.e., bug fixing)",,"GPT-3,GPT-3.5,GPT-4",,Occasionally (1-2 days a week),Agree,"Accuracy (i.e., outputs that the models generate are consistently correct),Controllability (i.e., behavior of the model can be directed by humans),Robustness (i.e., the model acts reliably under diverse scenarios),Source reputation (i.e., reputation of the platform/individual introducing the model)",,"My belief in the correctness of the code, after having provided the context in which the code is supposed to work. ",Yes,GPT 4 because it can generate accurate code in multiple languages ,Always,No,,,By the frequency of LLM usage for code generation tasks,,,,,,,,,,,,,Occasionally (1-2 days a week),Agree,"Accuracy (i.e., outputs that the models generate are consistently correct),Controllability (i.e., behavior of the model can be directed by humans),Robustness (i.e., the model acts reliably under diverse scenarios)",,"For me, trust in LLMs for Program repair is mainly related to the degree of accuracy that an LLM exhibits in producing code. ",Yes,GPT-4. because it can produce  accurate code in multiple coding languages ,Always,No,,,By the tendency/frequency to use it for assistance with program repairs,Strongly agree,"Multi-item measurement of diverse factors, such as  accuracy, interpretability, robustness, ethics, etc.      ",No,,Researcher,,Graduate or professional degree,Less than 1 year,25 to 34,Male,,None of these,Asian,
1,55,FALSE,anonymous,EN,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,18,FALSE,anonymous,EN,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,22,FALSE,anonymous,EN,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,32,FALSE,anonymous,EN,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
0,83,FALSE,anonymous,EN,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,489476,FALSE,anonymous,EN,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
